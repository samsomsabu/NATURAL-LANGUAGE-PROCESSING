{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1eyGfsI5vexwZW7Cw5cUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsomsabu/NATURAL-LANGUAGE-PROCESSING/blob/main/SAMSON_549_LAB1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, TweetTokenizer, RegexpTokenizer\n",
        "from nltk.tokenize import MWETokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from gensim.models import Word2Vec\n",
        "from keras.preprocessing.text import text_to_word_sequence"
      ],
      "metadata": {
        "id": "QzAqVy-Jv2nf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gfcyywldvhG3"
      },
      "outputs": [],
      "source": [
        "paragraph=\"Dragons, often depicted as fearsome and powerful creatures üêâüî•, have captured the imagination of people for centuries. With their towering presence and scaly bodies, dragons have been the focus of countless myths and legends. Despite their majestic appearance, dragons don't always fit the stereotype of being purely destructive; in some stories, they exhibit wisdom and protectiveness. In popular culture, dragons have been both feared and revered, often portrayed as guardians of treasure or formidable adversaries to brave heroes. The fascination with dragons persists, with their enigmatic nature and mythical allure continuing to captivate the hearts and minds of many.  \""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fQj8JfizR6A",
        "outputId": "0f7ebdee-5c1c-4e34-8cdc-f208a61286a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Tokenization:\n",
        "\n",
        "This generally involves breaking down a text into individual words."
      ],
      "metadata": {
        "id": "6R0xuTcEzt7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_tokenize(paragraph))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIU2RWoJx1Et",
        "outputId": "3a359fcf-7e61-4995-c085-9099e632984a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâüî•', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "XFNykgif2J3i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Process the paragraph using spaCy\n",
        "doc = nlp(paragraph)"
      ],
      "metadata": {
        "id": "C9Crpjjh3F64"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract words from the processed document\n",
        "tokens = [token.text for token in doc]\n",
        "\n",
        "# Display the result\n",
        "print(tokens)\n",
        "for i in range(0,len(tokens)):\n",
        "  print(tokens[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJUqaFKh3Mem",
        "outputId": "c8e7b4c5-f019-4e39-b6fc-5d1a1df27958"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâ', 'üî•', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.', ' ']\n",
            "Dragons\n",
            ",\n",
            "often\n",
            "depicted\n",
            "as\n",
            "fearsome\n",
            "and\n",
            "powerful\n",
            "creatures\n",
            "üêâ\n",
            "üî•\n",
            ",\n",
            "have\n",
            "captured\n",
            "the\n",
            "imagination\n",
            "of\n",
            "people\n",
            "for\n",
            "centuries\n",
            ".\n",
            "With\n",
            "their\n",
            "towering\n",
            "presence\n",
            "and\n",
            "scaly\n",
            "bodies\n",
            ",\n",
            "dragons\n",
            "have\n",
            "been\n",
            "the\n",
            "focus\n",
            "of\n",
            "countless\n",
            "myths\n",
            "and\n",
            "legends\n",
            ".\n",
            "Despite\n",
            "their\n",
            "majestic\n",
            "appearance\n",
            ",\n",
            "dragons\n",
            "do\n",
            "n't\n",
            "always\n",
            "fit\n",
            "the\n",
            "stereotype\n",
            "of\n",
            "being\n",
            "purely\n",
            "destructive\n",
            ";\n",
            "in\n",
            "some\n",
            "stories\n",
            ",\n",
            "they\n",
            "exhibit\n",
            "wisdom\n",
            "and\n",
            "protectiveness\n",
            ".\n",
            "In\n",
            "popular\n",
            "culture\n",
            ",\n",
            "dragons\n",
            "have\n",
            "been\n",
            "both\n",
            "feared\n",
            "and\n",
            "revered\n",
            ",\n",
            "often\n",
            "portrayed\n",
            "as\n",
            "guardians\n",
            "of\n",
            "treasure\n",
            "or\n",
            "formidable\n",
            "adversaries\n",
            "to\n",
            "brave\n",
            "heroes\n",
            ".\n",
            "The\n",
            "fascination\n",
            "with\n",
            "dragons\n",
            "persists\n",
            ",\n",
            "with\n",
            "their\n",
            "enigmatic\n",
            "nature\n",
            "and\n",
            "mythical\n",
            "allure\n",
            "continuing\n",
            "to\n",
            "captivate\n",
            "the\n",
            "hearts\n",
            "and\n",
            "minds\n",
            "of\n",
            "many\n",
            ".\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "blob = TextBlob(paragraph)\n",
        "\n",
        "# Tokenize the paragraph into words\n",
        "tokens = blob.words\n",
        "\n",
        "# Display the result\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr5On7-J3QaQ",
        "outputId": "fd4fc446-1cb0-4368-bdcb-99379e2ccd17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâüî•', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'Despite', 'their', 'majestic', 'appearance', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'In', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'The', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Tokenization:\n",
        "\n",
        "It involves splitting a text into sentences.\n",
        "we can use NLTK LIBRARY\n"
      ],
      "metadata": {
        "id": "Al9rMMdKz11j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K=[]"
      ],
      "metadata": {
        "id": "7mEsc-d31aKu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K=sent_tokenize(paragraph)\n",
        "L=len(K)\n",
        "for i in range(0,L):\n",
        "  print(K[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3HUIHZs2GYY",
        "outputId": "8dec583a-cc8f-41a5-8ce2-324b014509c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dragons, often depicted as fearsome and powerful creatures üêâüî•, have captured the imagination of people for centuries.\n",
            "With their towering presence and scaly bodies, dragons have been the focus of countless myths and legends.\n",
            "Despite their majestic appearance, dragons don't always fit the stereotype of being purely destructive; in some stories, they exhibit wisdom and protectiveness.\n",
            "In popular culture, dragons have been both feared and revered, often portrayed as guardians of treasure or formidable adversaries to brave heroes.\n",
            "The fascination with dragons persists, with their enigmatic nature and mythical allure continuing to captivate the hearts and minds of many.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the paragraph using spaCy\n",
        "doc = nlp(paragraph)\n",
        "\n",
        "# Extract sentences from the processed document\n",
        "sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "# Display the result\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7tJKLFSRD3F",
        "outputId": "b0a9a412-2505-44fd-ce3f-d5e097ae4a3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons, often depicted as fearsome and powerful creatures üêâüî•, have captured the imagination of people for centuries.', 'With their towering presence and scaly bodies, dragons have been the focus of countless myths and legends.', \"Despite their majestic appearance, dragons don't always fit the stereotype of being purely destructive; in some stories, they exhibit wisdom and protectiveness.\", 'In popular culture, dragons have been both feared and revered, often portrayed as guardians of treasure or formidable adversaries to brave heroes.', 'The fascination with dragons persists, with their enigmatic nature and mythical allure continuing to captivate the hearts and minds of many.  ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the paragraph into sentences\n",
        "sentences = blob.sentences\n",
        "\n",
        "# Display the result\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft8ktW0QRlzj",
        "outputId": "6b72b693-2ea4-4eb7-bea0-26280267c1fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sentence(\"Dragons, often depicted as fearsome and powerful creatures üêâüî•, have captured the imagination of people for centuries.\"), Sentence(\"With their towering presence and scaly bodies, dragons have been the focus of countless myths and legends.\"), Sentence(\"Despite their majestic appearance, dragons don't always fit the stereotype of being purely destructive; in some stories, they exhibit wisdom and protectiveness.\"), Sentence(\"In popular culture, dragons have been both feared and revered, often portrayed as guardians of treasure or formidable adversaries to brave heroes.\"), Sentence(\"The fascination with dragons persists, with their enigmatic nature and mythical allure continuing to captivate the hearts and minds of many.\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer"
      ],
      "metadata": {
        "id": "dNcgExfGRri3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = WordPunctTokenizer()\n",
        "tokens = tokenizer.tokenize(paragraph)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNX9o0YaSLR1",
        "outputId": "e4e43a72-4cb9-424b-edb4-d22aa68598e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâüî•,', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'don', \"'\", 't', 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the paragraph based on punctuation\n",
        "tokens = blob.words\n",
        "\n",
        "# Display the result\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVUpB180SgFI",
        "outputId": "e28348ee-ae89-46d8-ecf8-f8dbd93707c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâüî•', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'Despite', 'their', 'majestic', 'appearance', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'In', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'The', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treebank Word Tokenizer"
      ],
      "metadata": {
        "id": "j1Js9f61yjXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treebank Word Tokenizer\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "treebank_tokens = treebank_tokenizer.tokenize(paragraph)\n",
        "print(\"\\nTreebank Word Tokenizer:\", treebank_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L70eXrmZH-X",
        "outputId": "edfa87e2-dab7-4912-e533-e9ae03ddaf41"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Treebank Word Tokenizer: ['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâüî•', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tweet Tokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tweet_tokens = tweet_tokenizer.tokenize(paragraph)\n",
        "\n",
        "print(\"\\nTweet Tokenizer:\", tweet_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO3yhaExyhbR",
        "outputId": "1b36f3e1-dfac-4b2e-89c6-699049fed8be"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tweet Tokenizer: ['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâ', 'üî•', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', \"don't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Word Expression Tokenizer\n",
        "mwe_tokenizer = MWETokenizer([('majestic', 'creatures')])\n",
        "mwe_tokens = mwe_tokenizer.tokenize(tokens)\n",
        "print(\"\\nMulti-Word Expression Tokenizer:\", mwe_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5evDATnzFYe",
        "outputId": "b78b55f5-1ad6-45a8-a338-a6a9b6f04df5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multi-Word Expression Tokenizer: ['Dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâüî•', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'Despite', 'their', 'majestic', 'appearance', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'In', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'The', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TextBlob Word Tokenize\n",
        "textblob_tokens = TextBlob(paragraph).words\n",
        "print(\"\\nTextBlob Word Tokenize:\", textblob_tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcnWj33XzPTv",
        "outputId": "dced5ee8-4cd1-47d1-968e-9144640fcc8e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TextBlob Word Tokenize: ['Dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâüî•', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'Despite', 'their', 'majestic', 'appearance', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'In', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'The', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spaCy Tokenizer\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "spaCy_tokens = [token.text for token in nlp(paragraph)]\n",
        "print(\"\\nspaCy Tokenizer:\", spaCy_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGVKd_gqzRSo",
        "outputId": "fd078feb-4df4-474f-bbef-7d4b05a3f171"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy Tokenizer: ['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâ', 'üî•', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim Word Tokenizer\n",
        "gensim_model = Word2Vec(sentences=[tokens], min_count=1)\n",
        "gensim_tokens = list(gensim_model.wv.index_to_key)\n",
        "print(\"\\nGensim Word Tokenizer:\", gensim_tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nemmW9Z3zbwi",
        "outputId": "44952692-4217-43a7-e755-c0064582eb38"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gensim Word Tokenizer: ['and', 'of', 'dragons', 'the', 'have', 'their', 'often', 'as', 'been', 'with', 'to', 'myths', 'focus', 'countless', 'many', 'legends', 'scaly', 'Despite', 'majestic', 'appearance', 'do', \"n't\", 'bodies', 'centuries', 'presence', 'towering', 'With', 'fit', 'for', 'people', 'imagination', 'captured', 'üêâüî•', 'creatures', 'powerful', 'fearsome', 'depicted', 'always', 'being', 'stereotype', 'minds', 'or', 'formidable', 'adversaries', 'brave', 'heroes', 'The', 'fascination', 'persists', 'enigmatic', 'nature', 'mythical', 'allure', 'continuing', 'captivate', 'hearts', 'treasure', 'guardians', 'portrayed', 'exhibit', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'wisdom', 'revered', 'protectiveness', 'In', 'popular', 'culture', 'both', 'feared', 'Dragons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization with Keras\n",
        "keras_tokens = text_to_word_sequence(paragraph)\n",
        "print(\"\\nTokenization with Keras:\", keras_tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUS5FFtSzhHn",
        "outputId": "06d41383-a6b1-4e0d-d73b-8efcc87e40e0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenization with Keras: ['dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', 'üêâüî•', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'with', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'despite', 'their', 'majestic', 'appearance', 'dragons', \"don't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'in', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'the', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42p9oxWRzjkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing you need to do in any NLP project is text preprocessing. Preprocessing input text simply means putting the data into a predictable and analyzable form. It‚Äôs a crucial step for building an amazing NLP application.\n",
        "\n",
        "There are different ways to preprocess text:\n",
        "\n",
        "stop word removal,\n",
        "tokenization,\n",
        "stemming.\n",
        "Among these, the most important step is tokenization. It‚Äôs the process of breaking a stream of textual data into words, terms, sentences, symbols, or some other meaningful elements called tokens."
      ],
      "metadata": {
        "id": "lpFqFmZ20gZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization is the process of breaking down a text into smaller units called tokens. These tokens can be words, subwords, or even characters, depending on the level of granularity you need. Tokenization is a fundamental step in natural language processing (NLP) and is crucial for various language-related tasks such as text analysis, machine translation, sentiment analysis, and more.\n",
        "\n",
        "In the context of word tokenization, the goal is to split a sentence or a piece of text into individual words. For example, the sentence \"Tokenization is important for NLP\" would be tokenized into the following words: [\"Tokenization\", \"is\", \"important\", \"for\", \"NLP\"].\n",
        "\n",
        "Sentence tokenization involves breaking down a longer text into its constituent sentences. This process is essential when dealing with tasks that require understanding the structure and meaning of individual sentences.\n",
        "\n",
        "Tokenization helps convert raw text into a format that can be easily processed and analyzed by machines or algorithms. It serves as a foundational step in many NLP applications by providing a structured representation of textual data."
      ],
      "metadata": {
        "id": "rDp6SO-tTpRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we need tokenization?\n",
        "Tokenization is the first step in any NLP pipeline. It has an important effect on the rest of your pipeline. A tokenizer breaks unstructured data and natural language text into chunks of information that can be considered as discrete elements. The token occurrences in a document can be used directly as a vector representing that document.\n",
        "\n",
        "This immediately turns an unstructured string (text document) into a numerical data structure suitable for machine learning. They can also be used directly by a computer to trigger useful actions and responses. Or they might be used in a machine learning pipeline as features that trigger more complex decisions or behavior.\n",
        "\n",
        "Tokenization can separate sentences, words, characters, or subwords. When we split the text into sentences, we call it sentence tokenization. For words, we call it word tokenization.\n",
        "\n",
        "Different tools for tokenization\n",
        "Although tokenization in Python may be simple, we know that it‚Äôs the foundation to develop good models and help us understand the text corpus. This section will list a few tools available for tokenizing text content like NLTK, TextBlob, spacy, Gensim, and Keras.\n",
        "\n",
        "White Space Tokenization\n",
        "The simplest way to tokenize text is to use whitespace within a string as the ‚Äúdelimiter‚Äù of words. This can be accomplished with Python‚Äôs split function, which is available on all string object instances as well as on the string built-in class itself. You can change the separator any way you need.\n",
        "\n",
        "NLTK Word Tokenize\n",
        "NLTK (Natural Language Toolkit) is an open-source Python library for Natural Language Processing. It has easy-to-use interfaces for over 50 corpora and lexical resources such as WordNet, along with a set of text processing libraries for classification, tokenization, stemming, and tagging.\n",
        "\n",
        "You can easily tokenize the sentences and words of the text with the tokenize module of NLTK.\n",
        "\n",
        "Punctuation-based tokenizer\n",
        "This tokenizer splits the sentences into words based on whitespaces and punctuations.\n",
        "\n",
        "Treebank Word tokenizer\n",
        "This tokenizer incorporates a variety of common rules for english word tokenization. It separates phrase-terminating punctuation like (?!.;,) from adjacent tokens and retains decimal numbers as a single token. Besides, it contains rules for English contractions.\n",
        "\n",
        "Tweet tokenizer\n",
        "When we want to apply tokenization in text data like tweets, the tokenizers mentioned above can‚Äôt produce practical tokens. Through this issue, NLTK has a rule based tokenizer special for tweets. We can split emojis into different words if we need them for tasks like sentiment analysis.\n",
        "\n",
        "MWET tokenizer\n",
        "NLTK‚Äôs multi-word expression tokenizer (MWETokenizer) provides a function add_mwe() that allows the user to enter multiple word expressions before using the tokenizer on the text. More simply, it can merge multi-word expressions into single tokens.\n",
        "\n",
        "TextBlob Word Tokenize\n",
        "TextBlob is a Python library for processing textual data. It provides a consistent API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
        "\n",
        "spaCy Tokenizer\n",
        "SpaCy is an open-source Python library that parses and understands large volumes of text. With available models catering to specific languages (English, French, German, etc.), it handles NLP tasks with the most efficient implementation of common algorithms.\n",
        "\n",
        "spaCy tokenizer provides the flexibility to specify special tokens that don‚Äôt need to be segmented, or need to be segmented using special rules for each language, for example punctuation at the end of a sentence should be split off ‚Äì whereas ‚ÄúU.K.‚Äù should remain one token.\n",
        "\n",
        "Gensim word tokenizer\n",
        "Gensim is a Python library for topic modeling, document indexing, and similarity retrieval with large corpora. The target audience is the natural language processing (NLP) and information retrieval (IR) community. It offers utility functions for tokenization.\n",
        "\n",
        "Tokenization with Keras\n",
        "Keras open-source library is one of the most reliable deep learning frameworks. To perform tokenization we use: text_to_word_sequence method from the Class Keras.preprocessing.text class. The great thing about Keras is converting the alphabet in a lower case before tokenizing it, which can be quite a time-saver."
      ],
      "metadata": {
        "id": "kXdFrWH10ti8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenges and limitations"
      ],
      "metadata": {
        "id": "fMY3zulb17jI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, this task is used for text corpus written in English or French where these languages separate words by using white spaces, or punctuation marks to define the boundary of the sentences. Unfortunately, this method couldn‚Äôt be applicable for other languages like Chinese, Japanese, Korean Thai, Hindi, Urdu, Tamil, and others. This problem creates the need to develop a common tokenization tool that combines all languages.\n",
        "\n",
        "Another limitation is in the tokenization of Arabic texts since Arabic has a complicated morphology as a language. For example, a single Arabic word may contain up to six different tokens like the word ‚ÄúÿπŸÇÿØ‚Äù (eaqad)."
      ],
      "metadata": {
        "id": "9UdboeeT1kPu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQaiUbVe0Nd9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}